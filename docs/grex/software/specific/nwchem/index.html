<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Nwchem"><meta property="og:title" content><meta property="og:description" content="NWChem Introduction NWChem is a Scalable open-source solution for large scale molecular simulations. NWChem is actively developed by a consortium of developers and maintained by the EMSL located at the Pacific Northwest National Laboratory (PNNL) in Washington State. The code is distributed as open-source under the terms of the Educational Community License version 2.0 (ECL 2.0).
System specific notes On Grex software stack, NWChem is using OpenMPI 3.1 with Intel compilers toolchains."><meta property="og:type" content="article"><meta property="og:url" content="http://um-grex.github.io/grex-docs/docs/grex/software/specific/nwchem/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2022-02-16T11:44:23-06:00"><title>Nwchem | Unofficial Grex User Guide</title><link rel=icon href=/grex-docs/favicon.png type=image/x-icon><link rel=stylesheet href=/grex-docs/book.min.06cbd313f49ddc884804421299d5dc11b1cd097fdcfed7f054a79a137890a2d7.css integrity="sha256-BsvTE/Sd3IhIBEISmdXcEbHNCX/c/tfwVKeaE3iQotc="><script defer src=/grex-docs/en.search.min.fd6effed6df2b2261d8b14ac938fdd0eac5bfb4fd0ff7875145f807db4d1379c.js integrity="sha256-/W7/7W3ysiYdixSsk4/dDqxb+0/Q/3h1FF+AfbTRN5w="></script></head><body><input type=checkbox class=hidden id=menu-control><main class="flex container"><aside class="book-menu fixed"><nav><style>hr{border:0;height:3px;background-image:linear-gradient(to right,transparent,#095484,transparent)}</style><h2 class=book-brand><a href=http://um-grex.github.io/grex-docs><img src=/grex-docs/logo/um_logo_email_signature.png style=width:auto;height:auto alt=Logo><br><hr><span>Unofficial Grex User Guide</span><hr></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64><div class="book-search-spinner spinner hidden"></div><ul id=book-search-results></ul></div><hr><ul><li class=book-section-flat><a href=/grex-docs/docs/longread/>Notes of Grex Changes</a><ul><li class=book-section-flat><a href=/grex-docs/docs/longread/training/>Training Materials and Presentations</a><ul></ul></li></ul></li><li class=book-section-flat><a href=/grex-docs/docs/computecanada/>Accessing Compute Canada resources</a><ul></ul></li><li class=book-section-flat><a href=/grex-docs/docs/grex/>Grex HPC QuickStart</a><ul><li><a href=/grex-docs/docs/grex/access/>Access and Usage conditions</a></li><li><a href=/grex-docs/docs/grex/connecting/>Connecting / Transferring data</a></li><li><a href=/grex-docs/docs/grex/data/>Storage and Data</a></li><li><a href=/grex-docs/docs/grex/running/>Running Jobs</a></li><li><a href=/grex-docs/docs/grex/ood/>Grex's OpenOnDemand Web Portal</a></li><li><a href=/grex-docs/docs/grex/software/>Software</a><ul><li><a href=/grex-docs/docs/grex/software/cern-vmfs/>CVMFS and ComputeCanada</a></li><li><a href=/grex-docs/docs/grex/software/general-linux/>General Linux tools</a></li><li><a href=/grex-docs/docs/grex/software/containers/>Containers for Software</a></li><li><a href=/grex-docs/docs/grex/software/code-development/>Code Development on Grex</a></li><li><a href=/grex-docs/docs/grex/software/jupyter-notebook/>Using JuPyTer Notebooks</a></li><li><a href=/grex-docs/docs/grex/software/specific/>Software-specific notes</a><ul><li><a href=/grex-docs/docs/grex/software/specific/gaussian/>Gaussian</a></li><li><a href=/grex-docs/docs/grex/software/specific/julia/>Julia</a></li><li><a href=/grex-docs/docs/grex/software/specific/lammps/>Lammps</a></li><li><a href=/grex-docs/docs/grex/software/specific/matlab/>Matlab</a></li><li><a href=/grex-docs/docs/grex/software/specific/nwchem/ class=active>Nwchem</a></li><li><a href=/grex-docs/docs/grex/software/specific/orca/>Orca</a></li><li><a href=/grex-docs/docs/grex/software/specific/priroda/>Priroda</a></li><li><a href=/grex-docs/docs/grex/software/specific/vasp/>Vasp</a></li></ul></li></ul></li></ul></li><li><a href=/grex-docs/docs/faq/>Frequently Asked Questions</a></li><li><a href=/grex-docs/docs/localit/>Local IT Resources</a></li><li><a href=/grex-docs/docs/support-contacts/>Support and Training</a></li><li><a href=/grex-docs/docs/disclaimer/>Disclaimer</a></li></ul></nav><script>(function(){var a=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(b){localStorage.setItem("menu.scrollTop",a.scrollTop)}),a.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></aside><div class=book-page><article class=markdown><h1 id=nwchem>NWChem</h1><h2 id=introduction>Introduction</h2><p><a href=https://nwchemgit.github.io/ target=_blank rel=noopener>NWChem</a>
is a Scalable open-source solution for large scale molecular simulations. NWChem is actively developed by a consortium of developers and maintained by the EMSL located at the Pacific Northwest National Laboratory (PNNL) in Washington State. The code is distributed as open-source under the terms of the Educational Community License version 2.0 (ECL 2.0).</p><h2 id=system-specific-notes>System specific notes</h2><p>On Grex software stack, NWChem is using OpenMPI 3.1 with Intel compilers toolchains. To find out which versions re available, use <code>module spider nwchem</code> .</p><p>For a version 6.8.1, at the time of writing the following modules have to be loaded:</p><blockquote class="book-hint info"><code>module load intel/15.0 ompi/3.1.4 nwchem/6.8.1</code></blockquote><p>The NWChem on Grex was built with the ARMCI variant <a href=https://github.com/nwchemgit/nwchem/wiki/ARMCI target=_blank rel=noopener>MPI-PR</a>
. Thus, NWCHem needs at least One process per node reserved for the data communication. To run a serial job one needs 2 tasks per node. To run a 22 core job over two whole nodes, one has to ask for 2 nodes, 12 tasks per node. Simple number of tasks specification likely wont work because of the chance of having a single-task node allocated by SLURM; so <strong>--nodes= --ntask-per-node</strong> specification is required!</p><h2 id=sample-slurm-script>Sample SLURM Script</h2><blockquote class="book-hint slurm"><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:teal>#!/bin/bash
</span><span style=color:teal></span><span style=color:#080;font-style:italic>#SBATCH --ntasks-per-node=7 --nodes=2 --cpus-per-task=1</span>
<span style=color:#080;font-style:italic>#SBATCH --mem-per-cpu=2000mb</span>
<span style=color:#080;font-style:italic>#SBATCH --time=0-3:00:00</span>
<span style=color:#080;font-style:italic>#SBATCH --job-name=NWchem-dft-test</span>
<span style=color:#080;font-style:italic># Adjust the number of tasks, time and memory required.</span>
<span style=color:#080;font-style:italic># the above spec is for 12 compute tasks over two nodes.</span>
module load intel/15.0.5.223 ompi/3.1.4 nwchem/6.8.1
echo <span style=color:#00f>&#34;Starting run at: `date`&#34;</span>
which nwchem
<span style=color:#080;font-style:italic># Uncomment/Change these in case you want to use custom basis sets</span>
export NWCHEM_NWPW_LIBRARY=/global/software/cent7/nwchem/6.8.1-intel15-ompi314/data/libraryps/
export NWCHEM_BASIS_LIBRARY=/global/software/cent7/nwchem/6.8.1-intel15-ompi314/data/libraries/
<span style=color:#080;font-style:italic># In most cases SCRATCH_DIR would  be on local nodes scratch</span>
<span style=color:#080;font-style:italic># While results are in the same directory</span>
export NWCHEM_SCRATCH_DIR=$TMPDIR
export NWCHEM_PERMANENT_DIR=<span style=color:#00f>`</span>pwd<span style=color:#00f>`</span>
<span style=color:#080;font-style:italic># Optional memory setting; note that this one or the one in your code</span>
<span style=color:#080;font-style:italic># must match the #SBATCH --mem-per-cpu times compute tasks  !</span>
export NWCHEM_MEMORY_TOTAL=<span style=color:#00f>2000000000</span> <span style=color:#080;font-style:italic># 24000 MB, double precision words only</span>
export MKL_NUM_THREADS=<span style=color:#00f>1</span>
srun nwchem  dft_feco5.nw &gt; dft_feco5.$SLURM_JOBID.log
echo <span style=color:#00f>&#34;Program finished with exit code </span>$?<span style=color:#00f> at: `date`&#34;</span></code></pre></div></blockquote><p>Assuming the script above is saved as <strong>nwchem.job</strong>, it can be sumbitted with:</p><blockquote class="book-hint info"><code>sbatch nwchem.job</code></blockquote></article><div class="book-footer justify-between"><div><a class="flex align-center" href=https://github.com/um-grex/grex-docs/commit/4a07d74120d95d4386c1c274f941df41cb1cc57e title="Last modified by Shamov | Feb 16, 2022" target=_blank><img src=/grex-docs/svg/calendar.svg class=book-icon alt=Calendar>
<span>Feb 16, 2022</span></a></div><div><a class="flex align-center" href=https://github.com/um-grex/grex-docs/blob/master/content/docs/grex/software/specific/nwchem.md target=_blank><img src=/grex-docs/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><br><hr></div><aside class="book-toc levels-4 fixed"><nav id=TableOfContents><ul><li><a href=#nwchem>NWChem</a><ul><li><a href=#introduction>Introduction</a></li><li><a href=#system-specific-notes>System specific notes</a></li><li><a href=#sample-slurm-script>Sample SLURM Script</a></li></ul></li></ul></nav></aside></main></body></html>