<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Software on Grex</title><link>https://um-grex.github.io/grex-docs/categories/software/</link><description>Recent content in Software on Grex</description><generator>Hugo</generator><language>en</language><copyright>The MIT License (MIT) Copyright © 2023 UM-Grex</copyright><atom:link href="https://um-grex.github.io/grex-docs/categories/software/index.xml" rel="self" type="application/rss+xml"/><item><title>Running Quantum Espresso on Grex</title><link>https://um-grex.github.io/grex-docs/specific-soft/espresso/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/specific-soft/espresso/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>&lt;a
 href="https://www.quantum-espresso.org"
 class="is-pretty-link">Quantum ESPRESSO&lt;/a
>
 is an integrated suite of computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials (both norm-conserving and ultrasoft).&lt;/p>
&lt;h2 id='system-specific-notes'>System specific notes&lt;a href='#system-specific-notes' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>On the Grex&amp;rsquo;s default software stack (&lt;em>SBEnv&lt;/em>), Espresso is built using a variety of compilers and Open MPI 4.1&lt;/p>
&lt;p>To find out which versions are available, use &lt;strong>module spider espresso&lt;/strong>.&lt;/p>
&lt;p>For a version 7.3.1, at the time of writing the following modules should be loaded:&lt;/p></description></item><item><title>Running Gaussian on Grex</title><link>https://um-grex.github.io/grex-docs/specific-soft/gaussian/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/specific-soft/gaussian/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>&lt;a
 href="http://gaussian.com/"title="Gaussian" id="gaussian"
 class="is-pretty-link">Gaussian 16&lt;/a
>
 is a comprehensive suite for electronic structure modeling using &lt;strong>ab initio&lt;/strong>, DFT and semi-empirical methods. A list of Gaussian 16 features can be found &lt;a
 href="http://gaussian.com/g16glance/"title="Gaussian Features" id="gaussian-features"
 class="is-pretty-link">here&lt;/a
>
.&lt;/p>
&lt;h2 id='user-responsibilities-and-access'>User Responsibilities and Access&lt;a href='#user-responsibilities-and-access' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>University of Manitoba has a site license for Gaussian 16 and GaussView. However, it comes with certain license limitations, so access to the code is subject to some license conditions.&lt;/p>
&lt;p>Since, as of now, Compute Canada accounts are a superset of Grex accounts, users will want to initiate getting access by sending an email agreeing to Gaussian conditions to &lt;strong>support@tech.alliancecan.ca&lt;/strong>, confirming that you have read and agree to abide by the following conditions, and mentioning that you&amp;rsquo;d also want to access it on Grex:&lt;/p></description></item><item><title>Running GROMACS MD package on Grex</title><link>https://um-grex.github.io/grex-docs/specific-soft/gromacs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/specific-soft/gromacs/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>&lt;a
 href="https://www.gromacs.org"
 class="is-pretty-link">GROMACS&lt;/a
>
 (GROningen MAchine for Chemical Simulations) is a molecular dynamics package primarily designed for simulations of proteins, lipids and nucleic acids. GROMACS is one of the fastest and most popular software packages available and can run on CPUs as well as GPUs.&lt;/p>
&lt;h2 id='system-specific-notes'>System specific notes&lt;a href='#system-specific-notes' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>On the Grex&amp;rsquo;s default software stack (&lt;em>SBEnv&lt;/em>), GROMACS is built using a variety of compilers and OpenMPI 4.1&lt;/p>
&lt;p>To find out which versions are available, use &lt;strong>module spider gromacs&lt;/strong>. There could be more than one (for example, CPU and GPU) builds available for each GROMACS version as listed by &lt;em>module spider&lt;/em>.&lt;/p></description></item><item><title>Running Julia on Grex</title><link>https://um-grex.github.io/grex-docs/specific-soft/julia/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/specific-soft/julia/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>&lt;a
 href="https://julialang.org/"
 class="is-pretty-link">Julia&lt;/a
>
 is a programming language that was designed for performance, ease of use and portability. It is available as a module on Grex.&lt;/p>
&lt;h2 id='available-julia-versions'>Available Julia versions&lt;a href='#available-julia-versions' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>Presently, binary Julia version &lt;strong>julia/1.10.3&lt;/strong> is available. Use &lt;code>module spider julia&lt;/code> to find out other versions.&lt;/p>
&lt;h2 id='installing-packages'>Installing packages&lt;a href='#installing-packages' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>We do not maintain centralized versions of Julia packages. Users should install Julia modules in their home directory.&lt;/p>
&lt;p>The command is (in Julia REPL):&lt;/p></description></item><item><title>Running LAMMPS on Grex</title><link>https://um-grex.github.io/grex-docs/specific-soft/lammps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/specific-soft/lammps/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>&lt;a
 href="https://www.lammps.org/"
 class="is-pretty-link">LAMMPS&lt;/a
>
 is a classical molecular dynamics code. The name stands for Large-scale Atomic / Molecular Massively Parallel Simulator. LAMMPS is distributed by Sandia National Laboratories, a US Department of Energy laboratory.&lt;/p>
&lt;h2 id='modules'>Modules&lt;a href='#modules' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>On the Grex’s default software stack (SBEnv), LAMMPS was built using a variety of compilers and OpenMPI 4.1&lt;/p>
&lt;p>To find out which versions are available, use &lt;strong>module spider lammps&lt;/strong>&lt;/p>
&lt;p>As an example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>module load arch/avx512 gcc/13.2.0 openmpi/4.1.6 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>module load lammps/2021-09-29&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>and&lt;/p></description></item><item><title>General Linux tools</title><link>https://um-grex.github.io/grex-docs/software/general-linux/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/software/general-linux/</guid><description>&lt;h2 id='linux-tools-on-grex'>Linux tools on Grex&lt;a href='#linux-tools-on-grex' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>There are a number of general and distro-specific tools on Grex that are worth mentioning here. Such tools are: &lt;strong>text editors&lt;/strong>, &lt;strong>image viewers&lt;/strong>, &lt;strong>file managers&lt;/strong>, &amp;hellip; etc.&lt;/p>
&lt;h2 id='command-line-text-editors'>Command line Text editors&lt;a href='#command-line-text-editors' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>Command line text editors allow you to edit files right on Grex in any terminal session (such as SSH session or an X terminal under OOD):&lt;/p>
&lt;blockquote>
&lt;ul>
&lt;li>The (arguably) most popular editor is &lt;strong>vi&lt;/strong>, or &lt;strong>vim&lt;/strong>. It is very powerful, but requires some experience to use it. To exit a &lt;strong>vim&lt;/strong> session, you can use the &lt;strong>ZZ&lt;/strong> key combination (hold shift key + zz), or &lt;strong>ESC, :x!&lt;/strong>. There are many vi tutorials around, for &lt;a
 href="http://heather.cs.ucdavis.edu/~matloff/UnixAndC/Editors/ViIntro.html"
 class="is-pretty-link">example this one&lt;/a
>
 or &lt;a
 href="https://learnxinyminutes.com/docs/vim/"
 class="is-pretty-link">learn VIM in X minutes&lt;/a
>
 .&lt;/li>
&lt;/ul>&lt;/blockquote>
&lt;blockquote>
&lt;ul>
&lt;li>Another lightweight text-mode editor is &lt;strong>nano&lt;/strong>. It provides a self-explanatory key-combination menu at the bottom of the screen. An online manual can be found &lt;a
 href="https://www.nano-editor.org/dist/v2.1/nano.html"
 class="is-pretty-link">here&lt;/a
>
.&lt;/li>
&lt;/ul>&lt;/blockquote>
&lt;blockquote>
&lt;ul>
&lt;li>A more modern alternative to &amp;ldquo;nano&amp;rdquo; is &lt;strong>micro&lt;/strong> . On Grex it is available only as module (&lt;code>module load micro&lt;/code>) . &lt;strong>micro&lt;/strong> supports syntax coloring for a number of programming languages. The webpage of &lt;a
 href="https://micro-editor.github.io/"
 class="is-pretty-link">micro&lt;/a
>
 .&lt;/li>
&lt;/ul>&lt;/blockquote>
&lt;blockquote>
&lt;ul>
&lt;li>Midnight Commander file manager provides a text-mode editor that can be invoked stand-alone as &lt;strong>mc -e filename&lt;/strong>, or from within &lt;strong>mc&lt;/strong> by using F4 or Edit menu item on a selected file.&lt;/li>
&lt;/ul>&lt;/blockquote>
&lt;h2 id='gui-text-editors'>GUI Text editors&lt;a href='#gui-text-editors' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;!--
Sometimes it is useful (for example, for copy/paste operations with mouse, between client computer and a remote session) or convenient to have a text editor with a graphical user interface. Note that a most practical way to use this is from X2Go sessions that provide tolerable interaction speeds.
-->
&lt;p>Vi has a GUI counterpart which is accessible as &lt;strong>evim&lt;/strong> command. There are also the following GUI editors: &lt;strong>nedit&lt;/strong> and &lt;strong>xfe-xfw&lt;/strong>.&lt;/p></description></item><item><title>Running MATLAB on Grex</title><link>https://um-grex.github.io/grex-docs/specific-soft/matlab/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/specific-soft/matlab/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>&lt;a
 href="http://www.mathworks.com/"
 class="is-pretty-link">MATLAB&lt;/a
>
 is a general-purpose high-level programming package for numerical work such as linear algebra, signal processing and other calculations involving matrices or vectors of data. We have a campus license for MATLAB which is used on Grex and other local computing resources. &lt;!-- MATLAB is available only for UManitoba users.-->&lt;/p>
&lt;p>As with most of the Grex software, MATLAB is available as a module. The following command will load the latest version available on Grex:&lt;/p></description></item><item><title>Running NWChem on Grex</title><link>https://um-grex.github.io/grex-docs/specific-soft/nwchem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/specific-soft/nwchem/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>&lt;a
 href="https://nwchemgit.github.io/"
 class="is-pretty-link">NWChem&lt;/a
>
 is a Scalable, massive parallel and open source solution for large scale molecular simulations. NWChem is actively developed by a consortium of developers and maintained by the EMSL located at the Pacific Northwest National Laboratory (PNNL) in Washington State. The code is distributed as open source under the terms of the Educational Community License version 2.0 (ECL 2.0).&lt;/p>
&lt;h2 id='system-specific-notes'>System specific notes&lt;a href='#system-specific-notes' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>To find out which versions of NWChem are available, use &lt;strong>module spider nwchem&lt;/strong> .&lt;/p></description></item><item><title>Running ORCA on Grex</title><link>https://um-grex.github.io/grex-docs/specific-soft/orca/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/specific-soft/orca/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>&lt;a
 href="http://cec.mpg.de/forum/"
 class="is-pretty-link">ORCA&lt;/a
>
 is a flexible, efficient and easy-to-use general purpose tool for quantum chemistry with specific emphasis on spectroscopic properties of open-shell molecules. It features a wide variety of standard quantum chemical methods ranging from semi-empirical methods to DFT to single - and multi-reference correlated ab initio methods. It can also treat environmental and relativistic effects.&lt;/p>
&lt;h2 id='user-responsibilities-and-access'>User Responsibilities and Access&lt;a href='#user-responsibilities-and-access' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>ORCA is a proprietary software, even if it is free it still requires you to agree to the ORCA license conditions. We have installed ORCA on Grex, but to access the binaries, each of the ORCA users has to confirm they have accepted the license terms.&lt;/p></description></item><item><title>Running VASP on Grex</title><link>https://um-grex.github.io/grex-docs/specific-soft/vasp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/specific-soft/vasp/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>&lt;a
 href="https://www.vasp.at/wiki/index.php/The_VASP_Manual"
 class="is-pretty-link">VASP&lt;/a
>
 is a massively parallel plane-wave solid state DFT code. On Grex it is available only for the research groups that hold VASP licenses. To get access, PIs would need to send us a confirmation email from the VASP vendor, detailing the status of their license and a list of users allowed to use it.&lt;/p>
&lt;h2 id='system-specific-notes'>System specific notes&lt;a href='#system-specific-notes' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;!--On the Grex local software stack, we have VASP 5 and VASP 6 using Intel compiler and OpenMPI 3.1.--> 
&lt;p>To find out which versions of VASP are available, use &lt;code>module spider vasp&lt;/code> .&lt;/p></description></item><item><title>Modules and software stacks</title><link>https://um-grex.github.io/grex-docs/software/using-modules/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/software/using-modules/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;!--
&lt;div class="sc-collapsible-container">
 &lt;div class="sc-collapsible-header">Modules allow for clean and dynamic modification of the user&amp;#39;s Linux session environment&lt;/div>
 &lt;div class="sc-collapsible-content">&lt;/div>
&lt;/div>

-->
&lt;p>On a Linux server or a Linux desktop, software can be installed in one of the standard locations, such as &lt;em>/usr/bin&lt;/em>. This is where most of the system-level software binaries can be found. For custom user-built software it is a good practice to install it separately from the standard location, to avoid potential conflicts and make changes and uninstallation possible. One of the common locations would be under &lt;em>/usr/local/&lt;/em>, as in &lt;em>/usr/local/My_Custom_software/&lt;/em> , or under &lt;em>/opt&lt;/em> (&lt;em>/opt/My_Other_custom_software&lt;/em>).&lt;/p></description></item><item><title>Using Python for ML on Grex</title><link>https://um-grex.github.io/grex-docs/specific-soft/python-ai/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/specific-soft/python-ai/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>Python is a dynamic language with many optional Library &amp;ldquo;modules&amp;rdquo; available. Moreover, Python is often used as a &amp;ldquo;glue&amp;rdquo; language for interacting with tools and libraries written in other languages (C/C++, Fortran, CUDA, etc.).
This makes maintenance of Python software difficult. Not only do Python and libraries need to be of the right versions, but also other software they depend on should be of the same versions that have been used to build the corresponding packages.&lt;/p></description></item><item><title>Code Development on Grex</title><link>https://um-grex.github.io/grex-docs/software/code-development/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/software/code-development/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>Grex comes with a sizable software stack that contains most of the software development environment for typical HPC applications. This section of the documentation covers best practices for compiling and building your own software on Grex.&lt;/p>
&lt;p>On Grex, login nodes can be used to compile software and to run short interactive and/or test runs. All other jobs must be submitted to the &lt;a
 href="https://um-grex.github.io/grex-docs/running-jobs/batch-jobs/"
 class="is-pretty-link">batch&lt;/a
>
 system. User sessions on the login nodes are limited by &lt;em>cgroups&lt;/em> to prevent resource congestion. Thus, it sometimes makes sense to perform some of the code development in interactive jobs, in cases such as (but not limited to):&lt;/p></description></item><item><title>Containers for Software</title><link>https://um-grex.github.io/grex-docs/software/containers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/software/containers/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>Linux Containers are means to isolate software dependencies from the base Linux operating system. Several different Linux container engines exist, most notably &lt;a
 href="https://www.docker.com"
 class="is-pretty-link">Docker&lt;/a
>
 which was first to emerge as the most popular tool in the DevOps community.&lt;/p>
&lt;p>Since then, a lot of work had been done by major Linux players like Google, RedHat and others to develop an open standard for container runtimes, which developed based on Docker, &lt;a
 href="https://opencontainers.org/"
 class="is-pretty-link">OCI&lt;/a
>
.&lt;/p>
&lt;p>There are HPC-specific container engines/runtimes that offer similar or equivalent functionality but allow for easier integration with shared Linux HPC systems. At the time of writing, the most widely used of them is the &lt;a
 href="https://sylabs.io/guides/3.11/user-guide/"
 class="is-pretty-link">Singularity&lt;/a
>
 container system, developed by a company called SyLabs, and its fork, a Linux Foundation project called &lt;a
 href="https://apptainer.org/"
 class="is-pretty-link">Apptainer&lt;/a
>
.
They are &lt;a
 href="https://apptainer.org/docs/user/latest/singularity_compatibility.html"
 class="is-pretty-link">compatible&lt;/a
>
 with each other. Singularity/Apptainer provides functionality for running most Docker images by converting them to the Singularity Image format (SIF). However, Singularity/Apptainer own format is &lt;a
 href="https://apptainer.org/docs/user/latest/docker_and_oci.html#differences-and-limitations-vs-docker"
 class="is-pretty-link">not completely OCI-compatible&lt;/a
>
, so there exists Docker images that would not work properly.&lt;/p></description></item><item><title>CVMFS and the Alliance software stack</title><link>https://um-grex.github.io/grex-docs/software/cern-vmfs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/software/cern-vmfs/</guid><description>&lt;h2 id='cc-cernvmfs-on-grex'>CC CernVMFS on Grex&lt;a href='#cc-cernvmfs-on-grex' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>&lt;a
 href="https://cernvm.cern.ch/portal/filesystem"
 class="is-pretty-link">CVMFS or CernVM FS&lt;/a
>
 stands for CernVM File System. It provides a scalable, reliable and low-maintenance software distribution service. CVMFS was originally developed to assist High Energy Physics (HEP) collaborations to deploy software on the worldwide-distributed computing infrastructure used to run data processing applications. Since then it has been used as a a generic way of distributing software.
Presently, we use CernVMFS (CVMFS) to provide the Alliance&amp;rsquo;s (or Compute Canada&amp;rsquo;s) software stack. Through the Alliance CVMVS servers, several other publically available CVMFS software repositories are available as well.
The examples are a Singularity/Apptainer repository from &lt;a
 href="https://opensciencegrid.org/"title="OpenScienceGrid" id="opensciencegrid"
 class="is-pretty-link">OpenScienceGrid&lt;/a
>
, Extreme-Scale Scientific Software Stack &lt;a
 href="https://e4s-project.github.io/"
 class="is-pretty-link">E4S&lt;/a
>
, and a Genomics software colection (GenPipes/MUGQIC) from &lt;a
 href="https://computationalgenomics.ca/"
 class="is-pretty-link">C3G&lt;/a
>
. Note that we can only &amp;ldquo;pull&amp;rdquo; the software from these repositories. To actually add or change software, datasets, etc., or receive support, the respective organizations controlling these CVMFS repositories should be contacted directly.&lt;/p></description></item><item><title>How to use Jupyter notebooks on Grex?</title><link>https://um-grex.github.io/grex-docs/software/jupyter-notebook/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/software/jupyter-notebook/</guid><description>&lt;h1 id='jupyter-on-grex'>Jupyter on Grex&lt;a href='#jupyter-on-grex' class='anchor'>#&lt;/a>
&lt;/h1>&lt;hr>
&lt;p>&lt;a
 href="https://jupyter.org/"
 class="is-pretty-link">Jupyter&lt;/a
>
 is a Web-interface aimed to support interactive data science and scientific computing. Jupyter supports several dynamic languages, most notably Python, R and Julia. Jupyter offers a metaphor of &amp;ldquo;computational document&amp;rdquo; that combines code, data and visualizations, and can be published or shared with collaborators.&lt;/p>
&lt;p>Jupyter can be used either as a simple, individual notebook or as a multi-user Web server/Interactive Development Environment (IDE), such as JupyterHub/JupyterLab. The JupyterHub servers can use a variety of computational back-end configurations: from free-for-all shared workstation to job spawning interfaces to HPC schedulers like SLURM or container workflow systems like Kubernetes.&lt;/p></description></item><item><title>Running jobs on Grex</title><link>https://um-grex.github.io/grex-docs/running-jobs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/running-jobs/</guid><description>&lt;h2 id='why-running-jobs-in-batch-mode'>Why running jobs in batch mode?&lt;a href='#why-running-jobs-in-batch-mode' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>There are many reasons for adopting a batch mode for running jobs on a cluster. From providing user&amp;rsquo;s computations with fairness, traffic control to prevent resource congestion and wasting, enforcing organizational priorities, to better understanding the workload, utilization and resource needs for future capacity planning; the scheduler provides it all. After being long-time PBS/Moab users, we have switched to the &lt;a
 href="https://slurm.schedmd.com/documentation.html"
 class="is-pretty-link">SLURM&lt;/a
>
 batch system since &lt;strong>December 2019&lt;/strong> with the &lt;strong>Linux/SLURM update&lt;/strong> &lt;a
 href="https://um-grex.github.io/grex-docs/changes/linux-slurm-update/"
 class="is-pretty-link">project&lt;/a
>
.&lt;/p></description></item><item><title>Software and Applications</title><link>https://um-grex.github.io/grex-docs/software/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/software/</guid><description>&lt;h2 id='software'>Software&lt;a href='#software' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>In the HPC world, software is more often meant as codes that do some scientific or engineering computation, data processing and visualization (as opposed to web services, relational databases, client-server business systems, email and office, &amp;hellip; etc.)&lt;/p>
&lt;p>Tools and libraries used to develop HPC software are also software, and have several best practices associated with them. Some of that will be covered below. Without means to provide software to do computations, HPC systems would be rather useless.&lt;/p></description></item><item><title>Software Specific Notes</title><link>https://um-grex.github.io/grex-docs/specific-soft/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/specific-soft/</guid><description>&lt;h2 id='software-specific-notes'>Software specific notes&lt;a href='#software-specific-notes' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>This page refers to the usage of some specific programs installed on Grex, like ORCA, VASP, &amp;hellip; etc.&lt;/p>
&lt;hr>
&lt;h2 id='software--applications'>Software / Applications&lt;a href='#software--applications' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;div class="sc-treeview">&lt;ul
 >&lt;li class="">
 &lt;div class="sc-treeview-label">&lt;p class="is-marginless">
 &lt;a
 href="https://um-grex.github.io/grex-docs/specific-soft/espresso/"
 class="is-pretty-link"
 >Espresso&lt;/a
 >
 &lt;/p>
 &lt;/div>&lt;/li>&lt;li class="">
 &lt;div class="sc-treeview-label">&lt;p class="is-marginless">
 &lt;a
 href="https://um-grex.github.io/grex-docs/specific-soft/gaussian/"
 class="is-pretty-link"
 >Gaussian&lt;/a
 >
 &lt;/p>
 &lt;/div>&lt;/li>&lt;li class="">
 &lt;div class="sc-treeview-label">&lt;p class="is-marginless">
 &lt;a
 href="https://um-grex.github.io/grex-docs/specific-soft/gromacs/"
 class="is-pretty-link"
 >GROMACS&lt;/a
 >
 &lt;/p>
 &lt;/div>&lt;/li>&lt;li class="">
 &lt;div class="sc-treeview-label">&lt;p class="is-marginless">
 &lt;a
 href="https://um-grex.github.io/grex-docs/specific-soft/julia/"
 class="is-pretty-link"
 >Julia&lt;/a
 >
 &lt;/p>
 &lt;/div>&lt;/li>&lt;li class="">
 &lt;div class="sc-treeview-label">&lt;p class="is-marginless">
 &lt;a
 href="https://um-grex.github.io/grex-docs/specific-soft/lammps/"
 class="is-pretty-link"
 >LAMMPS&lt;/a
 >
 &lt;/p>
 &lt;/div>&lt;/li>&lt;li class="">
 &lt;div class="sc-treeview-label">&lt;p class="is-marginless">
 &lt;a
 href="https://um-grex.github.io/grex-docs/specific-soft/matlab/"
 class="is-pretty-link"
 >MATLAB&lt;/a
 >
 &lt;/p>
 &lt;/div>&lt;/li>&lt;li class="">
 &lt;div class="sc-treeview-label">&lt;p class="is-marginless">
 &lt;a
 href="https://um-grex.github.io/grex-docs/specific-soft/nwchem/"
 class="is-pretty-link"
 >NWChem&lt;/a
 >
 &lt;/p>
 &lt;/div>&lt;/li>&lt;li class="">
 &lt;div class="sc-treeview-label">&lt;p class="is-marginless">
 &lt;a
 href="https://um-grex.github.io/grex-docs/specific-soft/orca/"
 class="is-pretty-link"
 >ORCA&lt;/a
 >
 &lt;/p>
 &lt;/div>&lt;/li>&lt;li class="">
 &lt;div class="sc-treeview-label">&lt;p class="is-marginless">
 &lt;a
 href="https://um-grex.github.io/grex-docs/specific-soft/vasp/"
 class="is-pretty-link"
 >VASP&lt;/a
 >
 &lt;/p>
 &lt;/div>&lt;/li>&lt;li class="">
 &lt;div class="sc-treeview-label">&lt;p class="is-marginless">
 &lt;a
 href="https://um-grex.github.io/grex-docs/specific-soft/python-ai/"
 class="is-pretty-link"
 >Python for ML&lt;/a
 >
 &lt;/p>
 &lt;/div>&lt;/li>&lt;/ul>&lt;/div>

&lt;h2 id='external-links'>External links&lt;a href='#external-links' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;ul>
&lt;li>&lt;a
 href="https://docs.alliancecan.ca/wiki/Running_jobs"
 class="is-pretty-link">Running jobs&lt;/a
>
 (on the Alliance&amp;rsquo;s clusters)&lt;/li>
&lt;li>&lt;a
 href="https://slurm.schedmd.com/documentation.html"
 class="is-pretty-link">SLURM&lt;/a
>
 documentation.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;!-- Changes and update:
* Last revision: Aug 28, 2024. 
--></description></item><item><title>OpenOnDemand, HPC Portal</title><link>https://um-grex.github.io/grex-docs/ood/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/ood/</guid><description>&lt;h2 id='introduction'>Introduction&lt;a href='#introduction' class='anchor'>#&lt;/a>
&lt;/h2>&lt;hr>
&lt;p>&lt;a
 href="https://openondemand.org/"title="OpenOnDemand" id="openondemand"
 class="is-pretty-link">OpenOnDemand&lt;/a
>
 or &lt;strong>OOD&lt;/strong> for short, is an open source Web portal for High-Performance computing, developed at Ohio Supercomputing Center. OOD makes it easier for beginner HPC users to access the resources via a Web interface. OOD also allows for interactive, visualization and other Linux Desktop applications to be accessed on HPC systems via a convenient Web user interface.&lt;/p>
&lt;p>Since the end of &lt;strong>October 2021&lt;/strong>, OpenOnDemand version 2 is officially in production on Grex.
Since the beginning of &lt;strong>January 2023&lt;/strong>, OpenOnDemand version 3 is officially in production on Grex.&lt;/p></description></item></channel></rss>