<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Information on Grex</title><link>https://um-grex.github.io/grex-docs/categories/information/</link><description>Recent content in Information on Grex</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>The MIT License (MIT) Copyright © 2022 um-grex</copyright><atom:link href="https://um-grex.github.io/grex-docs/categories/information/index.xml" rel="self" type="application/rss+xml"/><item><title>Digital Research Alliance of Canada</title><link>https://um-grex.github.io/grex-docs/friends/alliancecan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/friends/alliancecan/</guid><description>Introduction # Digital Research Alliance of Canada (the Alliance) is a Canadian National Digital Research Infrastructure (DRI) organization (formerly known as Compute Canada). It provides the eligible researchers with the research computing resources such as several High-performance computing (HPC) systems with a large curated HPC software stack, private OpenStack cloud, and Globus data transfer software.
The Alliance also maintains a user authentication service and usage database called CCDB. On Grex, we rely on CCDB for accessing our system.</description></item><item><title>Linux/SLURM update project</title><link>https://um-grex.github.io/grex-docs/changes/linux-slurm-update/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/changes/linux-slurm-update/</guid><description>Grex changes: Linux/SLURM update project. # December 10-11, 2019
Introduction / Motivation # Grex runs an old version of CentOS 6, which gets unsupported in 2020. The 2.6.x Linux kernel that is shipped with CentOS 6 does not support containerized workloads that require recent kernel features. The Lustre parallel filesystem client had some troubles that we were unable to resolve with the CentOS 6 kernel version as well. Finally, the original Grex resource management software, Torque 2.</description></item><item><title>Data sizes and quotas</title><link>https://um-grex.github.io/grex-docs/storage/data-sizes-and-quota/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/storage/data-sizes-and-quota/</guid><description>Data size and quotas # This section explains how to find the actual space and inode usage of your /home/ and /global/scratch allocations on Grex. We limit the size of the data and the number of files that can be stored on these filesystems.
File system Type Total space Quota per user /home NFSv4/RDMA 15 TB 100 GB /global/scratch Lustre 418 TB 4 TB /project Lustre 1 PB - To figure out where your current usage stands with the limit, POSIX quota or Lustre&amp;rsquo;s analog, lfs quota, commands can be used.</description></item><item><title>Grex: High Performance Computing Cluster at University of Manitoba</title><link>https://um-grex.github.io/grex-docs/grex/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/grex/</guid><description>Introduction # Grex is a UManitoba High Performance Computing (HPC) system, first put in production in early 2011 as part of WestGrid consortium. &amp;ldquo;Grex&amp;rdquo; is a Latin name for &amp;ldquo;herd&amp;rdquo; (or maybe &amp;ldquo;flock&amp;rdquo;?). The names of the Grex login nodes ( bison, tatanka, aurochs, yak) also refer to various kinds of bovine animals.
Since being defunded by WestGrid (on April 2, 2018), Grex is now available only to the users affiliated with University of Manitoba and their collaborators.</description></item><item><title>Access and Usage Conditions</title><link>https://um-grex.github.io/grex-docs/access/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/access/</guid><description>Access Conditions # Grex is open to all researchers at University of Manitoba and their collaborators. The main purpose of the Grex system is Research; it might be used for grad studies courses with a strong research component, for their course-based research.
The access and job accounting is by research group; that is, the Principal Investigator (PI)&amp;rsquo;s accounting group gets resource usage of their group members accounted for. Grex&amp;rsquo;s resources (CPU and GPU time, disk space, software licenses) are automatically managed by a batch scheduler, SLURM, according to the University&amp;rsquo;s priorities.</description></item><item><title>Connecting to Grex and Transferring data</title><link>https://um-grex.github.io/grex-docs/connecting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/connecting/</guid><description>Connecting to Grex # In order to use almost any HPC system, you would need to be able to somehow connect and log in to it. Also, it would be necessary to be able to transfer data to and from the system. The standard means for these tasks are provided by the SSH protocol.
To log in to Grex in the text (or bash) mode, connect to grex.hpc.umanitoba.ca using an SSH (Secure SHELL) client.</description></item><item><title>Data sharing</title><link>https://um-grex.github.io/grex-docs/storage/data-sharing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/storage/data-sharing/</guid><description>Data sharing # Sharing of accounts login information (like passwords or SSH keys) is strictly forbidden on Grex, as well as on most of the HPC systems. There is a mechanism of data/file sharing that does not require sharing of the accounts. To access each other&amp;rsquo;s data on Grex, the UNIX groups and permissions mechanism can be used as explained below.
UNIX groups # Each UNIX (or Linux) file or directory is owned by an individual user and also by a group (which may be composed of several users).</description></item><item><title>Local IT Resources</title><link>https://um-grex.github.io/grex-docs/friends/localit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/friends/localit/</guid><description>Introduction # In addition to the HPC Research Computing facility, there are other IT providers that might relate to research.
Resources provided by IST # IST provides a number of services related to Administrative IT, Teaching, and Research Computing as well.
For more information about IST, please visit UM IST Help website and IST service catalog.
Resources provided by the Libraries # Libraries provide a variety of services related to Research Data Management, as well as a GIS service: UM Libraries Research Services.</description></item><item><title>Getting Help</title><link>https://um-grex.github.io/grex-docs/support/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/support/</guid><description>The Alliance support # The single point support contact for the Alliance is support@tech.alliancecan.ca
Emailing to this address will create a support ticket in the Alliance ticketing system (Help Desk). We support both local (Grex) and National resources through the Alliance support ticketing system. This is the main support contact for our HPC group and it is a preferred method (as compared to contacting an HPC analyst directly). If you use your UManitoba email address (email registered in CCDB) to contact the Alliance support, it will reach us faster because the system will automatically detect it and assign your user name to the generated ticket.</description></item><item><title>Frequently Asked Questions.</title><link>https://um-grex.github.io/grex-docs/faq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/faq/</guid><description/></item><item><title>Friendly Organizations</title><link>https://um-grex.github.io/grex-docs/friends/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/friends/</guid><description/></item><item><title>Linux/SLURM update project</title><link>https://um-grex.github.io/grex-docs/changes/changes-before-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/changes/changes-before-2020/</guid><description>Grex defunded since April 2, 2018 # Since being defunded by WestGrid (on April 2, 2018), Grex is now available only to the users affiliated with University of Manitoba and their collaborators. The old WestGrid documentation, hosted on the WestGrid website became irrelevant after the Grex upgrade, so please visit Grex’s New Documentation. Thus, if you are an experienced user in the previous “version” of Grex, you might benefit from reading this document: Description of Grex changes.</description></item><item><title>Disclaimer</title><link>https://um-grex.github.io/grex-docs/disclaimer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/disclaimer/</guid><description>This website is a place for technical information related to certain Research Computing resources, maintained for the benefit of the researchers at the University of Manitoba, UofM and their external collaborators. The information, which is technical in nature, represents advice on best practices for using the Research Computing resources (HPC). Parts of the website are preliminary/draft texts released provisionally, in order to speed up the documentation process, and may contain inaccuracies and errors.</description></item><item><title>Glossary</title><link>https://um-grex.github.io/grex-docs/glossary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://um-grex.github.io/grex-docs/glossary/</guid><description> A # AI :: Artificial Intelligence AVX :: Advanced Vector eXtensions B # BLAS :: Basic Linear Algebra Subprograms C # CPU :: Central Processing Unit D # DFT :: 1. Discrete Fourier Transform, 2. Density Functional Theory E # F # FFT :: Fast Fourier Transform G # GCC :: GNU Compiler Collection GPU :: Graphics Processing Unit GUI :: Graphical User Interface H # HPC :: High-Performance Computing HTTPS :: Hypertext Transfer Protocol Secure HTTP :: Hypertext Transfer Protocol I # I/O :: Input/Output IST :: Information Services and Technology J # K # L # M # MDS :: Metadata Server MDT :: Metadata Target ML :: Machine Learning MPI :: Message-Passing Interface N # NVMe :: Non-Volatile Memory express O # OMP :: Open Multi-Processing OOD :: Open OnDemand OSS :: Object Storage Server OST :: Object Storage Target P # PI :: Principal Investigator Q # R # RAC :: Resource Allocation Competition S # SLURM :: Simple Linux Utility for Resource Management SSH :: Secure SHell T # TLS :: Transport Layer Security U # V # VM :: Virtual Machine W # X # Y # Z #</description></item></channel></rss>